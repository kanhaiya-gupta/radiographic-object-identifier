{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "386a190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "from scipy.spatial.distance import pdist\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dc3355a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pores: 10\n",
      "Uniqueness percent: 97.77777777777777 %\n",
      " \n",
      "Total pores: 11\n",
      "Uniqueness percent: 98.18181818181819 %\n",
      " \n",
      "Total pores: 12\n",
      "Uniqueness percent: 96.96969696969697 %\n",
      " \n",
      "Total pores: 13\n",
      "Uniqueness percent: 96.15384615384616 %\n",
      " \n",
      "Total pores: 14\n",
      "Uniqueness percent: 95.6043956043956 %\n",
      " \n",
      "Total pores: 15\n",
      "Uniqueness percent: 93.33333333333333 %\n",
      " \n",
      "Total pores: 16\n",
      "Uniqueness percent: 93.33333333333333 %\n",
      " \n",
      "Total pores: 17\n",
      "Uniqueness percent: 92.6470588235294 %\n",
      " \n",
      "Total pores: 18\n",
      "Uniqueness percent: 91.50326797385621 %\n",
      " \n",
      "Total pores: 19\n",
      "Uniqueness percent: 89.47368421052632 %\n",
      " \n",
      "Total pores: 20\n",
      "Uniqueness percent: 88.94736842105263 %\n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "data1 = pd.read_csv(\"../Data/Segmented_Data/Machine/XCT-3.csv\")\n",
    "data2 = pd.read_csv(\"../Data/Segmented_Data/Machine/XCT-16.csv\")\n",
    "\n",
    "# Data\\Segmented_Data\\Machine\n",
    "\n",
    "#data\n",
    "\n",
    "cond11 = data1[\"Voxel count\"] >= 27\n",
    "cond12 = data1[\"Sphericity\"] >= 0.7\n",
    "\n",
    "cond21 = data2[\"Voxel count\"] >= 27\n",
    "cond22 = data2[\"Sphericity\"] >= 0.7\n",
    "\n",
    "\n",
    "\n",
    "data_11 = data1[cond11 & cond12]\n",
    "data_22 = data2[cond21 & cond22]\n",
    "    \n",
    "    \n",
    "\n",
    "data1A = data_11.sort_values(by=[\"Volume (µm³)\"], ascending=False)\n",
    "data2A = data_22.sort_values(by=[\"Volume (µm³)\"], ascending=False)\n",
    "\n",
    "data_A = pd.DataFrame(data1A) \n",
    "data_B = pd.DataFrame(data2A)\n",
    "\n",
    "\n",
    "\n",
    "#data_A[:1]\n",
    "\n",
    "\n",
    "# Load the main segmented CT data\n",
    "\n",
    "intital_sampling = 1000\n",
    "\n",
    "for i in range(10, 21, 1):\n",
    "    #print(i)\n",
    "    total_pore = i\n",
    "    \n",
    "    df_A = data_A[:total_pore]\n",
    "    df_B = data_B[:total_pore]\n",
    "\n",
    "    df_A.to_csv('./Data/Data_synthetic/Orient_sample/Machine/Sample/data_A_total_'+ str(i).zfill(2) +'.csv', index=False)\n",
    "    df_B.to_csv('./Data/Data_synthetic/Orient_sample/Machine/Sample/data_B_total_'+ str(i).zfill(2) +'.csv', index=False)\n",
    "        \n",
    "    ## Sample 1 \n",
    "\n",
    "    QR_data_absolute = pd.read_csv('./Data/Data_synthetic/Orient_sample/Machine/Sample/data_A_total_'+ str(i).zfill(2) +'.csv', usecols = [\"Center Of Mass X (µm)\", \"Center Of Mass Y (µm)\", \"Center Of Mass Z (µm)\"])\n",
    "\n",
    "    pair_dist = QR_data_absolute.to_numpy()\n",
    "        \n",
    "    pair_distance = pdist(pair_dist)\n",
    "\n",
    "    #pair_distance = np.round(pdist(pair_dist), 10)   \n",
    "\n",
    "    matrix_dist_vol = np.zeros(6*len(pair_distance))\n",
    "\n",
    "    #print(len(matrix_dist_vol))\n",
    "\n",
    "    Volume_pores = np.array(df_A[\"Volume (µm³)\"])\n",
    "\n",
    "    #print(Volume_pores)\n",
    "\n",
    "    matrix_dist_vol = matrix_dist_vol.reshape(-1, 6)\n",
    "\n",
    "    pores_array = np.arange(0, len(df_A))\n",
    "\n",
    "    #print(pores_array)\n",
    "\n",
    "    list_1 = pores_array\n",
    "    list_2 = pores_array\n",
    " \n",
    "    unique_combinations = []\n",
    " \n",
    "    for p in range(len(list_1)):\n",
    "        for q in range(len(list_2)):\n",
    "            if p >= q:\n",
    "                continue\n",
    "            unique_combinations.append([0., 0., 0., 0., list_1[p], list_2[q]])\n",
    "\n",
    "    unique_combinations = np.array(unique_combinations)\n",
    "\n",
    "    #print(\"3d array: \", unique_combinations)\n",
    "\n",
    "    for p, dist_value in enumerate(pair_distance):\n",
    "        index_volume_1 = unique_combinations[p][4] \n",
    "        index_volume_2 = unique_combinations[p][5]\n",
    "        #print(index_volume_1)\n",
    "        #print(Volume_pores[index_volume_2])\n",
    "        matrix_dist_vol[p][0] = index_volume_1 + 1\n",
    "        matrix_dist_vol[p][1] = index_volume_2 + 1\n",
    "        matrix_dist_vol[p][2] = pair_distance[p]\n",
    "        #print(Volume_pores[int(index_volume_1)])\n",
    "        matrix_dist_vol[p][3] = Volume_pores[int(index_volume_1)]\n",
    "        matrix_dist_vol[p][4] = Volume_pores[int(index_volume_2)]\n",
    "\n",
    "    matrix_dist_vol[:,5] = matrix_dist_vol[:,3] + matrix_dist_vol[:,4]\n",
    "\n",
    "    #print(\"Matrix \", matrix_dist_vol)\n",
    "    # export as csv file\n",
    "    dist_vol_data = {'index_1':matrix_dist_vol[:,0], 'index_2':matrix_dist_vol[:,1],'distance':matrix_dist_vol[:,2], 'volume_1':matrix_dist_vol[:,3], 'volume_2':matrix_dist_vol[:,4], 'pair-wise_volume':matrix_dist_vol[:,5]}\n",
    "    df_pair_distance = pd.DataFrame(dist_vol_data)\n",
    "\n",
    "    df_pair_distance.to_csv('./Data/Data_synthetic/Orient_sample/Machine/Reduced/data_A_total_'+ str(i).zfill(2) +'.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    ## Sample 2\n",
    "\n",
    "    QR_data_absolute = pd.read_csv('./Data/Data_synthetic/Orient_sample/Machine/Sample/data_B_total_'+ str(i).zfill(2) +'.csv', usecols = [\"Center Of Mass X (µm)\", \"Center Of Mass Y (µm)\", \"Center Of Mass Z (µm)\"])\n",
    "\n",
    "\n",
    "    pair_dist = QR_data_absolute.to_numpy()\n",
    "        \n",
    "    pair_distance = pdist(pair_dist)\n",
    "\n",
    "    #pair_distance = np.round(pdist(pair_dist), 10)   \n",
    "\n",
    "    matrix_dist_vol = np.zeros(6*len(pair_distance))\n",
    "\n",
    "    #print(len(matrix_dist_vol))\n",
    "\n",
    "    Volume_pores = np.array(df_B[\"Volume (µm³)\"])\n",
    "\n",
    "    #print(Volume_pores)\n",
    "\n",
    "    matrix_dist_vol = matrix_dist_vol.reshape(-1, 6)\n",
    "\n",
    "    pores_array = np.arange(0,len(df_B))\n",
    "\n",
    "    #print(pores_array)\n",
    "\n",
    "    list_1 = pores_array\n",
    "    list_2 = pores_array\n",
    " \n",
    "    unique_combinations = []\n",
    " \n",
    "    for p in range(len(list_1)):\n",
    "        for q in range(len(list_2)):\n",
    "            if p >= q:\n",
    "                continue\n",
    "            unique_combinations.append([0., 0., 0., 0., list_1[p], list_2[q]])\n",
    "\n",
    "    unique_combinations = np.array(unique_combinations)\n",
    "\n",
    "    #print(\"3d array: \", unique_combinations)\n",
    "\n",
    "    for p, dist_value in enumerate(pair_distance):\n",
    "        index_volume_1 = unique_combinations[p][4] \n",
    "        index_volume_2 = unique_combinations[p][5]\n",
    "        #print(index_volume_1)\n",
    "        #print(Volume_pores[index_volume_2])\n",
    "        matrix_dist_vol[p][0] = index_volume_1 + 1\n",
    "        matrix_dist_vol[p][1] = index_volume_2 + 1\n",
    "        matrix_dist_vol[p][2] = pair_distance[p]\n",
    "        #print(Volume_pores[int(index_volume_1)])\n",
    "        matrix_dist_vol[p][3] = Volume_pores[int(index_volume_1)]\n",
    "        matrix_dist_vol[p][4] = Volume_pores[int(index_volume_2)]\n",
    "\n",
    "    matrix_dist_vol[:,5] = matrix_dist_vol[:,3] + matrix_dist_vol[:,4]\n",
    "\n",
    "    #print(\"Matrix \", matrix_dist_vol)\n",
    "    # export as csv file\n",
    "    dist_vol_data = {'index_1':matrix_dist_vol[:,0], 'index_2':matrix_dist_vol[:,1],'distance':matrix_dist_vol[:,2], 'volume_1':matrix_dist_vol[:,3], 'volume_2':matrix_dist_vol[:,4], 'pair-wise_volume':matrix_dist_vol[:,5]}\n",
    "    df_pair_distance = pd.DataFrame(dist_vol_data)\n",
    "\n",
    "    df_pair_distance.to_csv('./Data/Data_synthetic/Orient_sample/Machine/Reduced/data_B_total_'+ str(i).zfill(2) +'.csv', index=False)\n",
    "        \n",
    "    #### check the uniqueness of the selected pore by position: x,y,z and volume\n",
    "\n",
    "    files = ['XCT-1']\n",
    "\n",
    "    Uniqueness_result = DataFrame(columns = files)\n",
    "                \n",
    "    #### code starts here\n",
    "    with open('./Data/Data_synthetic/Orient_sample/Machine/Reduced/data_A_total_'+ str(i).zfill(2) +'.csv') as mainfile:\n",
    "        csvReader_main = csv.reader(mainfile, delimiter=',')\n",
    "        for l, row_main in enumerate(csvReader_main):\n",
    "            if l == 0:\n",
    "                continue\n",
    "            #print(row_main)\n",
    "                \n",
    "            D = float(row_main[2])\n",
    "            V1 = float(row_main[3])\n",
    "            V2 = float(row_main[4])\n",
    "            VP = float(row_main[5])\n",
    "            r1 = np.round(((3*V1)/(4*np.pi))**(1/3))\n",
    "            r2 = np.round(((3*V2)/(4*np.pi))**(1/3))\n",
    "            diff_vol1_b = 4/3*np.pi*(r1+10.)**3 \n",
    "            diff_vol1_s = 4/3*np.pi*(r1-10.)**3\n",
    "            diff_vol2_b = 4/3*np.pi*(r2+10.)**3 \n",
    "            diff_vol2_s = 4/3*np.pi*(r2-10.)**3\n",
    "\n",
    "            Check_unique_point = []\n",
    "\n",
    "            Test_result = []\n",
    "            n = -99.\n",
    "\n",
    "            with open('./Data/Data_synthetic/Orient_sample/Machine/Reduced/data_B_total_'+ str(i).zfill(2) +'.csv') as otherfiles:\n",
    "                csvReader_other = csv.reader(otherfiles, delimiter=',')\n",
    "                for m, row_other in enumerate(csvReader_other):\n",
    "                    if m == 0:\n",
    "                        continue\n",
    "                    #print(row_other)\n",
    "                        \n",
    "                    D_t = float(row_other[2])\n",
    "                    V1_t = float(row_other[3])\n",
    "                    V2_t = float(row_other[4])\n",
    "                    VP_t = float(row_main[5])\n",
    "\n",
    "                    cond_D = False\n",
    "                    cond_VP = False\n",
    "                    cond_V1 = False\n",
    "                    cond_V2 = False\n",
    "\n",
    "                    #uncertainty_dist = config_QID[\"Uncertainty_window\"]*(np.sqrt(2*3*config_QID[\"Resolution_XCT\"]**2))\n",
    "                    uncertainty_dist = 1*10. # sqrt\n",
    "                    uncertainty_VP = 1000. # sqrt\n",
    "\n",
    "                    cond_D = np.abs(D - D_t) <= uncertainty_dist\n",
    "                    cond_VP = np.abs(VP - VP_t) < uncertainty_VP\n",
    "\n",
    "                    if ((V1_t >= diff_vol1_s) & (V1_t <= diff_vol1_b)):\n",
    "                        cond_V1 = True\n",
    "                        if ((V2_t >= diff_vol2_s) & (V2_t <= diff_vol2_b)):\n",
    "                            cond_V2 = True\n",
    "                    elif ((V1_t >= diff_vol2_s) & (V1_t <= diff_vol2_b)):\n",
    "                        cond_V1 = True\n",
    "                        if ((V2_t >= diff_vol1_s) & (V2_t <= diff_vol1_b)):\n",
    "                            cond_V2 = True\n",
    "\n",
    "                    final_cond = cond_D & cond_V1 & cond_V2\n",
    "\n",
    "                    #if cond_D:\n",
    "                    if final_cond:\n",
    "                        Test_result.append(True)\n",
    "                        n = m\n",
    "                        #ll = ll + 1\n",
    "                        #print(i, j)\n",
    "                    else:\n",
    "                        Test_result.append(False)\n",
    "                        \n",
    "#                     if n != -99.:\n",
    "#                          #print(\"Same pores:\", j)\n",
    "#                         print(l,n)\n",
    "                \n",
    "                Check_unique_point.append(any(Test_result)) \n",
    "                #print(Check_unique_point)\n",
    "\n",
    "            Uniqueness_result.loc[len(Uniqueness_result)] = Check_unique_point\n",
    "\n",
    "    Uniqueness_result.index += 1  \n",
    "    no_of_cols = len(Uniqueness_result.axes[1])\n",
    "    \n",
    "    print(\"Total pores:\", total_pore)\n",
    "\n",
    "    for t in range(no_of_cols):\n",
    "        false_count = 0\n",
    "        truth_count = 0\n",
    "        false_count = (Uniqueness_result[Uniqueness_result.columns[t]]).value_counts()[False] \n",
    "        #print(\"length\", len(Uniqueness_result))\n",
    "        if (false_count != len(Uniqueness_result)):\n",
    "            #print(\"hello\")\n",
    "            truth_count = (Uniqueness_result[Uniqueness_result.columns[t]]).value_counts()[True]\n",
    "                 \n",
    "        unique_percent = (false_count * 100)/(truth_count + false_count)\n",
    "        #print(\"Truth:\", truth_count)\n",
    "        #print(\"False:\", false_count)\n",
    "        print(\"Uniqueness percent:\", unique_percent,\"%\") \n",
    "        print(\" \") \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55413a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d109481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff8631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
