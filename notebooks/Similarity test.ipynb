{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c506a6-8912-41d4-9355-8282ce4867dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from module_list import *\n",
    "from functions import *\n",
    "\n",
    "class SimilarityTest:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.input_path = config[\"Input_Path\"]\n",
    "        self.output_path = config[\"Output_Path\"]\n",
    "        self.num_pores = config[\"No_of_pores\"]\n",
    "        self.sample_name = config[\"Sample_name\"]\n",
    "        self.uncertainty_window = config[\"Uncertainty_window\"]\n",
    "        self.resolution_xct = config[\"Resolution_XCT\"]\n",
    "        \n",
    "        self.similarity_dir = os.path.join(self.input_path, \"Processed_Data\", f\"Pores_{self.num_pores}\", \"Similarity\")\n",
    "        self.result_dir = os.path.join(self.output_path, f\"Pores_{self.num_pores}\", \"Similarity_result\")\n",
    "        self.csv_output_dir = os.path.join(self.output_path, f\"Pores_{self.num_pores}\", \"CSV_data\")\n",
    "        \n",
    "        if not self.config[\"Similarity_study\"]:\n",
    "            exit()\n",
    "    \n",
    "    def load_samples(self):\n",
    "        _, _, files = next(os.walk(self.similarity_dir))\n",
    "        files.remove(self.sample_name + \".csv\")\n",
    "        if not files:\n",
    "            print(\"There is only one sample and nothing to test\")\n",
    "            exit()\n",
    "        return files\n",
    "    \n",
    "    def compute_similarity(self):\n",
    "        files = self.load_samples()\n",
    "        main_sample = pd.read_csv(os.path.join(self.similarity_dir, f\"{self.sample_name}.csv\"))\n",
    "        dataframes_list = [pd.read_csv(os.path.join(self.similarity_dir, f)) for f in files]\n",
    "        \n",
    "        Uniqueness_result = DataFrame(columns=files)\n",
    "        uncertainty_dist = self.uncertainty_window * self.resolution_xct\n",
    "        \n",
    "        with open(os.path.join(self.similarity_dir, f\"{self.sample_name}.csv\")) as mainfile:\n",
    "            csvReader_main = csv.reader(mainfile, delimiter=',')\n",
    "            for i, row_main in enumerate(csvReader_main):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                D, V1, V2 = map(float, row_main[2:5])\n",
    "                \n",
    "                r1 = np.round(((3 * V1) / (4 * np.pi)) ** (1 / 3))\n",
    "                r2 = np.round(((3 * V2) / (4 * np.pi)) ** (1 / 3))\n",
    "                diff_vol1_b = (4 / 3) * np.pi * (r1 + uncertainty_dist) ** 3\n",
    "                diff_vol1_s = (4 / 3) * np.pi * (r1 - uncertainty_dist) ** 3\n",
    "                diff_vol2_b = (4 / 3) * np.pi * (r2 + uncertainty_dist) ** 3\n",
    "                diff_vol2_s = (4 / 3) * np.pi * (r2 - uncertainty_dist) ** 3\n",
    "                \n",
    "                Check_unique_point = []\n",
    "                for test_file in files:\n",
    "                    Test_result = []\n",
    "                    with open(os.path.join(self.similarity_dir, test_file)) as otherfile:\n",
    "                        csvReader_other = csv.reader(otherfile, delimiter=',')\n",
    "                        for j, row_other in enumerate(csvReader_other):\n",
    "                            if j == 0:\n",
    "                                continue\n",
    "                            D_t, V1_t, V2_t = map(float, row_other[2:5])\n",
    "                            \n",
    "                            cond_D = abs(D - D_t) <= uncertainty_dist\n",
    "                            cond_V1 = (diff_vol1_s <= V1_t <= diff_vol1_b) or (diff_vol1_s <= V2_t <= diff_vol1_b)\n",
    "                            cond_V2 = (diff_vol2_s <= V2_t <= diff_vol2_b) or (diff_vol2_s <= V1_t <= diff_vol2_b)\n",
    "                            \n",
    "                            final_cond = cond_D and cond_V1 and cond_V2\n",
    "                            Test_result.append(final_cond)\n",
    "                    \n",
    "                    Check_unique_point.append(any(Test_result))\n",
    "                \n",
    "                Uniqueness_result.loc[len(Uniqueness_result)] = Check_unique_point\n",
    "        \n",
    "        Uniqueness_result.index += 1  \n",
    "        Uniqueness_result.to_csv(os.path.join(self.csv_output_dir, f\"{self.sample_name}_similarity_result.csv\"), index=False)\n",
    "        self.write_results(Uniqueness_result, files)\n",
    "    \n",
    "    def write_results(self, Uniqueness_result, files):\n",
    "        result_file = os.path.join(self.result_dir, f\"{self.sample_name}_SIMILARITY.txt\")\n",
    "        with open(result_file, \"a\") as file_old:\n",
    "            for i, file in enumerate(files):\n",
    "                false_count = Uniqueness_result[file].value_counts().get(False, 0)\n",
    "                truth_count = Uniqueness_result[file].value_counts().get(True, 0)\n",
    "                unique_percent = (truth_count * 100) / (truth_count + false_count) if (truth_count + false_count) > 0 else 0\n",
    "                file_old.write(f\"{file}  {round(unique_percent, 2)}%\\n\")\n",
    "        \n",
    "        self.remove_duplicates(result_file)\n",
    "    \n",
    "    def remove_duplicates(self, file_path):\n",
    "        with open(file_path, \"r\") as file_read:\n",
    "            lines = set(file_read.readlines())\n",
    "        with open(file_path, \"w\") as out:\n",
    "            out.writelines(lines)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    similarity_test = SimilarityTest(config_QID)\n",
    "    similarity_test.compute_similarity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80163aaa-ddca-4538-8501-d371cf936e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ded95c-7bd2-4ec5-9d24-75610904f7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed39b2c-52f8-4618-bafd-de309919be8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795386e-011d-477b-874b-45300df9c2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e617e-5450-4d08-ac8e-b0c3efb175f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea06c27-4a4b-4287-b3c0-0f980dc4d9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae3a13-7f7c-41fc-81a5-240245915776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: similarity.py\n",
    "Author: Kanhaiya Gupta\n",
    "Date: 2023-08-29\n",
    "Description: A Python script applying the authentication concept.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from module_list import *\n",
    "from functions import *\n",
    "\n",
    "if not config_QID[\"Similarity_study\"]:\n",
    "    exit()\n",
    "\n",
    "# assign path\n",
    "path, dirs, files = next(os.walk(config_QID[\"Input_Path\"] + \"Processed_Data\" + \"/\" + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\"  + \"Similarity/\"))\n",
    "files.remove(config_QID[\"Sample_name\"] + \".csv\")\n",
    "\n",
    "#print(files)\n",
    "nos_samples = len(files)  # file count\n",
    "\n",
    "if nos_samples < 1:\n",
    "    print(\"There is only one sample and nothing to test\")\n",
    "    exit()\n",
    "\n",
    "# KS-test \n",
    "\n",
    "# create empty list\n",
    "dataframes_list = []\n",
    "\n",
    "main_sample = pd.read_csv(config_QID[\"Input_Path\"] + \"Processed_Data\" + \"/\" + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\" + \"Similarity/\" + config_QID[\"Sample_name\"] + \".csv\")\n",
    "\n",
    "for i in range(nos_samples):\n",
    "    temp_df = pd.read_csv(config_QID[\"Input_Path\"] + \"Processed_Data\" + \"/\" + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\"  + \"Similarity/\" + files[i])\n",
    "    dataframes_list.append(temp_df)\n",
    "     \n",
    "\n",
    "# append datasets to the list\n",
    "\n",
    "Uniqueness_result = DataFrame(columns = files)\n",
    "# Load the main segmented CT data\n",
    " \n",
    "with open(config_QID[\"Input_Path\"] + \"Processed_Data\" + \"/\" + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\" + \"Similarity/\" + config_QID[\"Sample_name\"] + \".csv\") as mainfile:\n",
    "    csvReader_main = csv.reader(mainfile, delimiter=',')\n",
    "    for i, row_main in enumerate(csvReader_main):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        #print(row_main)\n",
    "\n",
    "        D = float(row_main[2])\n",
    "        V1 = float(row_main[3])\n",
    "        V2 = float(row_main[4])\n",
    "\n",
    "        uncertainty_dist = config_QID[\"Uncertainty_window\"]*(config_QID[\"Resolution_XCT\"]) \n",
    "\n",
    "        r1 = np.round(((3*V1)/(4*np.pi))**(1/3))\n",
    "        r2 = np.round(((3*V2)/(4*np.pi))**(1/3))\n",
    "        diff_vol1_b = 4/3*np.pi*(r1 + uncertainty_dist)**3 \n",
    "        diff_vol1_s = 4/3*np.pi*(r1 - uncertainty_dist)**3\n",
    "        diff_vol2_b = 4/3*np.pi*(r2 + uncertainty_dist)**3 \n",
    "        diff_vol2_s = 4/3*np.pi*(r2 - uncertainty_dist)**3\n",
    "        \n",
    "        Sample_unique = True\n",
    "        Check_unique_point = []\n",
    "        for k in range(nos_samples):\n",
    "            Test_result = []\n",
    "\n",
    "            with open(config_QID[\"Input_Path\"] + \"Processed_Data\" + \"/\" + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\"  + \"Similarity/\" + files[k]) as otherfiles:\n",
    "                csvReader_other = csv.reader(otherfiles, delimiter=',')\n",
    "                for j, row_other in enumerate(csvReader_other):\n",
    "                    if j == 0:\n",
    "                        continue\n",
    "                    #print(row_other)\n",
    "\n",
    "                    D_t = float(row_other[2])\n",
    "                    V1_t = float(row_other[3])\n",
    "                    V2_t = float(row_other[4])\n",
    "                    \n",
    "\n",
    "                    cond_D = False\n",
    "                    cond_V1 = False\n",
    "                    cond_V2 = False\n",
    "\n",
    "                    cond_D = np.abs(D - D_t) <= uncertainty_dist\n",
    "                \n",
    "                    if ((V1_t >= diff_vol1_s) & (V1_t <= diff_vol1_b)):\n",
    "                        cond_V1 = True\n",
    "                        if ((V2_t >= diff_vol2_s) & (V2_t <= diff_vol2_b)):\n",
    "                            cond_V2 = True\n",
    "                    elif ((V2_t >= diff_vol1_s) & (V2_t <= diff_vol1_b)):\n",
    "                        cond_V1 = True\n",
    "                        if ((V2_t >= diff_vol2_s) & (V2_t <= diff_vol2_b)):\n",
    "                            cond_V2 = True\n",
    "\n",
    "                    final_cond = cond_D & cond_V1 & cond_V2\n",
    "                    \n",
    "\n",
    "                    if final_cond:\n",
    "                        Test_result.append(True)\n",
    "                    else:\n",
    "                        Test_result.append(False)\n",
    "\n",
    "            Check_unique_point.append(any(Test_result)) \n",
    "\n",
    "        Uniqueness_result.loc[len(Uniqueness_result)] = Check_unique_point\n",
    "        #Sample_unique = Sample_unique * Check_unique_point[0]\n",
    "        #print(\"The test result is: \", Check_unique_point[0])\n",
    "\n",
    "Uniqueness_result.index += 1  \n",
    "Uniqueness_result.to_csv(config_QID[\"Output_Path\"] + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\" + \"CSV_data/\"+ config_QID[\"Sample_name\"] + \"_similarity_result.csv\", index=False)\n",
    "\n",
    "no_of_cols = len(Uniqueness_result.axes[1])\n",
    "\n",
    "file_old = open(config_QID[\"Output_Path\"] + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\" + \"Similarity_result/\" + config_QID[\"Sample_name\"] + \"_SIMILARITY.txt\",\"a\")\n",
    "\n",
    "\n",
    "for i in range(no_of_cols):\n",
    "    false_count = 0\n",
    "    truth_count = 0\n",
    "    false_count = (Uniqueness_result[Uniqueness_result.columns[i]]).value_counts()[False]\n",
    "    if (false_count != len(Uniqueness_result)):\n",
    "        truth_count = (Uniqueness_result[Uniqueness_result.columns[i]]).value_counts()[True]\n",
    "    unique_percent = (truth_count * 100)/(truth_count + false_count)\n",
    "    file_old.write(Uniqueness_result.columns[i] + \"  \")\n",
    "    file_old.write(str(round(unique_percent, 2)) +  \"%\" + \"\\n\")\n",
    "\n",
    "file_old.close()\n",
    "\n",
    "\n",
    "\n",
    "file_read = open(config_QID[\"Output_Path\"] + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\" + \"Similarity_result/\" + config_QID[\"Sample_name\"] + \"_SIMILARITY.txt\",\"r\")\n",
    "lines = file_read.readlines()\n",
    "#print(lines)\n",
    "lines_set = set(lines)\n",
    "file_read.close()\n",
    "#print(lines_set)\n",
    "\n",
    "out = open(config_QID[\"Output_Path\"] + \"Pores_\" + str(config_QID[\"No_of_pores\"]) + \"/\" + \"Similarity_result/\" + config_QID[\"Sample_name\"] + \"_SIMILARITY.txt\",\"w\")\n",
    "\n",
    "for line in lines_set:\n",
    "    out.write(line)\n",
    "    #print(line)\n",
    "    \n",
    "out.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
